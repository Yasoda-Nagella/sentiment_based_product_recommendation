# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bWSkgMBo7Y8NVy3YgLSCOn5dxuy8-LfD

## **XGBoost with TF-IDF**
"""

#importing dataset
import pandas as pd
import io
from google.colab import files
uploaded = files.upload()
Final_model = pd.read_csv(io.BytesIO(uploaded['final_cleaned_product_review.csv']))

# Commented out IPython magic to ensure Python compatibility.
##importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier
from sklearn.metrics import *
from sklearn.feature_selection import SelectKBest
from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer
from sklearn.dummy import DummyClassifier
from string import punctuation
from sklearn import svm
from textblob import Word
import re
from sklearn.model_selection import train_test_split
from wordcloud import WordCloud
import textblob
from textblob import TextBlob
#from imblearn.pipeline import Pipeline as imbPipeline
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBClassifier

# % matplotlib inline

"""sentiment of the review. Before applying any machine learning models, ,let's check the sentiment of the first few reviews"""

Final_model['review_text'][:5].apply(lambda x: TextBlob(x).sentiment)

Final_model['rating_class'] = Final_model['rating_class'].apply(lambda x: 0 if x == 'bad' else 1)

# Splitting the Data Set into Train and Test Sets
X = Final_model['review_text']
y = Final_model['rating_class']

"""
**Splitting Dataset into Train and Test Set**

We split our data in to a training set used to fit our model and a test set to see how well it generalizes to unseen data.
"""

# Splitting Dataset into train and test set 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Print train and test set shape
print ('Train Set Shape\t\t:{}\nTest Set Shape\t\t:{}'.format(X_train.shape, X_test.shape))

def text_process(text):
    text = text.lower()
    text = re.sub('[^a-z]+', ' ', text).strip()
    return text

X = X.apply(lambda x: text_process(x))

tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english')

"""### **Checking Class Impabalce**

Let's check if there is any class imbalance here. If there is any class imbalance, then I will resolve that issue and will run the model again and will check the model performance.
"""

y.value_counts()

import nltk
nltk.download('wordnet')

X = Final_model['review_text']
X = X.apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split()]))

"""## **Handling imbalanced data with SMOTE**"""

#Handling imbalanced data using SMOTE
tfidf_n_grams = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english', ngram_range=(1, 2))
X_features = tfidf_n_grams.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size = 0.2, random_state=43)
sm = SMOTE()
X_train_smote, y_train_smote = sm.fit_sample(X_train, y_train)
X_test_smote, y_test_smote = sm.fit_sample(X_test, y_test)

"""**Dummy Classifier**"""

clf = DummyClassifier(strategy = 'stratified', random_state =42)
clf.fit(X_train_smote, y_train_smote)
y_pred = clf.predict(X_test_smote)
score = f1_score(y_test_smote, y_pred, average = 'weighted')
    
# Printing evaluation metric (f1-score) 
print("f1 score: {}".format(score))

"""#### **Function to perform machine learning models with balanced data**"""

def class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, ml_model):
    
    clf = ml_model.fit(X_train_smote, y_train_smote)
    clf_pred = clf.predict(X_test_smote)
    accuracy = clf.score(X_test_smote, y_test_smote)
    model_performance = classification_report(y_test_smote, clf_pred)
    validation_pred_proba_grad = clf.predict_proba(X_test_smote)
    roc_auc = roc_auc_score(y_test_smote, validation_pred_proba_grad[:,1])
    
    print ('accuracy of the model: ', accuracy)
    print('')
    print(model_performance)
    print('')
    print('ROC_AUC score: ', roc_auc)

    global y_pred
    # Predicting the Test set results
    y_pred = ml_model.predict(X_test_smote)
    
    # Assign f1 score to a variable
    score = f1_score(y_test_smote, y_pred, average = 'weighted')
    
    # Printing evaluation metric (f1-score) 
    print("f1 score: {}".format(score))

"""
**Confusion Matrix Plot Function**

Understanding the types of errors our model makes, and least desirable are important . A good way to visualize that information is using a Confusion Matrix, which compares the predictions our model makes with the true label. With that in mind, we used confusion matrix besides our evaluation metric (f1 score).
"""

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title = 'Confusion matrix',
                          cmap = plt.cm.ocean):
    """
    Create a confusion matrix plot for 'good' and 'bad' rating values 
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]
    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)
    plt.title(title, fontsize = 20)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, fontsize = 20)
    plt.yticks(tick_marks, classes, fontsize = 20)
    
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.

    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment = "center", 
                 color = "white" if cm[i, j] < thresh else "black", fontsize = 10)
    
    plt.tight_layout()
    plt.ylabel('True Label', fontsize = 10)
    plt.xlabel('Predicted Label', fontsize = 10)

    return plt

def disp_confusion_matrix(y_pred, model_name, vector = 'TF-IDF'):
    """
    Display confusion matrix for selected model with countVectorizer
    """
    cm = confusion_matrix(y_test_smote, y_pred)
    fig = plt.figure(figsize=(8, 8))
    plot = plot_confusion_matrix(cm, classes=['Bad','Good'], normalize=False, 
                                 title = model_name + " " + 'with' + " " + vector + " "+ '\nConfusion Matrix')
    plt.show()

class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, XGBClassifier(learning_rate =0.1,n_estimators=1000,max_depth=5,
                                                                                                 min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,
                                                                                                 nthread=4,scale_pos_weight=1,
                                                                                                 seed=27))
# Assign y_pred to a variable for further process
y_pred_tfidf_xgb = y_pred

# Print confusion matrix for XGBoost with TF-IDF
import itertools
disp_confusion_matrix(y_pred_tfidf_xgb, "XGBoost", "TF-IDF")

def model_pred(X_train, y_train, X_test, y_test, model):
    #if model == LogisticRegression:
    #    model = model()
    #else:
    #    model = model(n_estimators = trees)
    model = model()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_probs = model.predict_proba(X_test)[:,1]
    return y_pred, y_pred_probs

def ROC_curve_plots(y_test,y_pred_probs1,model1):
    fpr1, tpr1, _ = roc_curve(y_test, y_pred_probs1)
    auc1 = roc_auc_score(y_test, y_pred_probs1)

    plt.figure(1,figsize=(12,8))
    plt.plot([0, 1], [0, 1], 'k--')
    plt.plot(fpr1, tpr1, label=f'{model1} AUC={round(auc1,3)}')
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.title('ROC curve')
    plt.legend(loc='best')
    plt.show()
    return

y_pred1, y_pred_probs1 = model_pred(X_train_smote, y_train_smote, X_test_smote, y_test_smote, XGBClassifier)

ROC_curve_plots(y_test_smote,y_pred_probs1, 'Xgboost')

"""# **Recommendation System**
- User based recommendation
- User based prediction & evaluation
"""

# import libraties
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#importing dataset
import pandas as pd
import io
final_recommendation = pd.read_csv(io.BytesIO(uploaded['final_cleaned_product_review.csv']))

#drop these columns not needed for analysis
final_recommendation.drop(['brand','categories','reviews_date','user_sentiment','rating_class','Unnamed: 0','review_text'], axis=1, inplace=True)

final_recommendation.shape

final_recommendation = final_recommendation.rename(columns={'id': 'product_id', 'name': 'product_name' })

final_recommendation.head()

"""## **Dividing the dataset into train and test**"""

# Test and Train split of the dataset.
from sklearn.model_selection import train_test_split
train, test = train_test_split(final_recommendation, test_size=0.30, random_state=42)

print(train.shape)
print(test.shape)

# Pivot the train ratings' dataset into matrix format in which columns are products and the rows are reviews_username.
df_pivot = train.pivot(
    index='reviews_username',
    columns='product_id',
    values='reviews_rating'
).fillna(0)

df_pivot.head(3)

"""### Creating dummy train & dummy test dataset
These dataset will be used for prediction 
- Dummy train will be used later for prediction of the products which has not been rated by the user. To ignore the products rated by the user, we will mark it as 0 during prediction. The products not rated by user is marked as 1 for prediction in dummy train dataset. 

- Dummy test will be used for evaluation. To evaluate, we will only make prediction on the products rated by the user. So, this is marked as 1. This is just opposite of dummy_train.
"""

# Copy the train dataset into dummy_train
dummy_train = train.copy()

dummy_train.head()

# The products not rated by user is marked as 1 for prediction. 
dummy_train['reviews_rating'] = dummy_train['reviews_rating'].apply(lambda x: 0 if x>=1 else 1)

# Convert the dummy train dataset into matrix format.
dummy_train = dummy_train.pivot(
    index='reviews_username',
    columns='product_id',
    values='reviews_rating'
).fillna(1)

dummy_train.head()

"""**Cosine Similarity**

Cosine Similarity is a measurement that quantifies the similarity between two vectors [Which is Rating Vector in this case] 

**Adjusted Cosine**

Adjusted cosine similarity is a modified version of vector-based similarity where we incorporate the fact that different users have different ratings schemes. In other words, some users might rate items highly in general, and others might give items lower ratings as a preference. To handle this nature from rating given by user , we subtract average ratings for each user from each user's rating for different movies.

## **User Similarity Matrix**
"""

df_pivot.index.nunique()

from sklearn.metrics.pairwise import pairwise_distances

# Creating the User Similarity Matrix using pairwise_distance function.
user_correlation = 1 - pairwise_distances(df_pivot, metric='cosine')
user_correlation[np.isnan(user_correlation)] = 0
print(user_correlation)

user_correlation.shape

"""## Using adjusted Cosine 

### Here, we are not removing the NaN values and calculating the mean only for the movies rated by the user
"""

# Create a user-product matrix.
df_pivot = train.pivot(
    index='reviews_username',
    columns='product_id',
    values='reviews_rating'
)

mean = np.nanmean(df_pivot, axis=1)
df_subtracted = (df_pivot.T-mean).T

"""### Finding cosine similarity"""

from sklearn.metrics.pairwise import pairwise_distances

# Creating the User Similarity Matrix using pairwise_distance function.
user_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')
user_correlation[np.isnan(user_correlation)] = 0
print(user_correlation)

user_correlation.shape

"""## **Prediction - User User**

Doing the prediction for the users which are positively related with other users, and not the users which are negatively related as we are interested in the users which are more similar to the current users. So, ignoring the correlation for values less than 0.
"""

user_correlation[user_correlation<0]=0
user_correlation

user_predicted_ratings = np.dot(user_correlation, df_pivot.fillna(0))
user_predicted_ratings

user_predicted_ratings.shape

user_predicted_ratings

user_final_rating = np.multiply(user_predicted_ratings,dummy_train)
user_final_rating.head()

"""### **Finding the top 5 recommendation for the *user***"""

# Take the user ID as input.
user_input = str(input("Enter your user name"))
print(user_input)

user_final_rating.head(7)

d = user_final_rating.loc[user_input].sort_values(ascending=False)[0:5]
d

recommendation_df = pd.read_csv(io.BytesIO(uploaded['final_cleaned_product_review.csv']))

recommendation_df.drop(['brand','reviews_date','user_sentiment','rating_class','Unnamed: 0','review_text','reviews_rating','reviews_username'], axis=1, inplace=True)

recommendation_df = recommendation_df.rename(columns={'id': 'product_id', 'name': 'product_name' })

recommendation_df.drop(['product_name'], axis=1, inplace=True)

recommendation_df.head()

d = pd.merge(d,recommendation_df,left_on='product_id',right_on='product_id', how = 'left')
d.head()

df = pd.merge(train,recommendation_df,left_on='product_id',right_on='product_id',how='left')
df[df.reviews_username == 'angel'] .head()

"""## **Evaluation - User User**

"""

# Find out the common users of test and train dataset.
common = test[test.reviews_username.isin(train.reviews_username)]
common.shape

common.head()

# convert into the user-product matrix.
common_user_based_matrix = common.pivot_table(index='reviews_username', columns='product_id', values='reviews_rating')

common_user_based_matrix.head()

# Convert the user_correlation matrix into dataframe.
user_correlation_df = pd.DataFrame(user_correlation)

user_correlation_df['reviews_username'] = df_subtracted.index

user_correlation_df.set_index('reviews_username',inplace=True)
user_correlation_df.head()

list_name = common.reviews_username.tolist()

user_correlation_df.columns = df_subtracted.index.tolist()


user_correlation_df_1 =  user_correlation_df[user_correlation_df.index.isin(list_name)]

user_correlation_df_2 = user_correlation_df_1.T[user_correlation_df_1.T.index.isin(list_name)]

user_correlation_df_3 = user_correlation_df_2.T

user_correlation_df_3.shape

user_correlation_df_3[user_correlation_df_3<0]=0

common_user_predicted_ratings = np.dot(user_correlation_df_3, common_user_based_matrix.fillna(0))
common_user_predicted_ratings

dummy_test = common.copy()

dummy_test['reviews_rating'] = dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)

dummy_test = dummy_test.pivot_table(index='reviews_username', columns='product_id', values='reviews_rating').fillna(0)

common_user_based_matrix.head()

common_user_predicted_ratings = np.multiply(common_user_predicted_ratings,dummy_test)

from sklearn.preprocessing import MinMaxScaler
from numpy import *

X  = common_user_predicted_ratings.copy() 
X = X[X>0]

scaler = MinMaxScaler(feature_range=(1, 5))
print(scaler.fit(X))
y = (scaler.transform(X))

print(y)

common_ = common.pivot_table(index='reviews_username', columns='product_id', values='reviews_rating')

# Finding total non-NaN value
total_non_nan = np.count_nonzero(~np.isnan(y))

rmse = (sum(sum((common_ - y )**2))/total_non_nan)**0.5
print(rmse)

